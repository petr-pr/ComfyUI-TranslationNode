# ğŸˆ¯ ComfyUI Translation Node (Offline)
Offline translation node for [ComfyUI](https://github.com/comfyanonymous/ComfyUI), powered by **Facebook's M2M-100** multilingual model. Translate text between 100+ languages â€” completely **offline and private**.

## ğŸš€ Features
- ğŸŒ Translate between 100+ languages
- ğŸ§  Automatic source language detection
- âš¡ Works entirely offline once the model is downloaded
- ğŸ§© Seamless integration with text/image/video workflows in ComfyUI
- ğŸ’¾ Cached model for faster reuse

## ğŸ› ï¸ Installation
1. **Copy or clone** this repository into your ComfyUI custom nodes folder:
   ```
   ComfyUI/custom_nodes/ComfyUI-TranslationNode/
   ```
2. **Install dependencies**:
   ```
   pip install -r requirements.txt
   ```
3. **Prepare the model files** (see the next section).
4. Restart ComfyUI and look for **ğŸˆ¯ Translation Node (Offline)** under the *Text* category.

## ğŸ§± Local Model Setup
This node uses **Facebookâ€™s M2M-100 (418M)** multilingual translation model.

1. **Download the model** manually from Hugging Face: ğŸ”— https://huggingface.co/facebook/m2m100_418M
2. Create the following folder structure inside your ComfyUI installation:
   ```
   ComfyUI/
   â”œâ”€â”€ custom_nodes/
   â”‚   â””â”€â”€ ComfyUI-TranslationNode/
   â””â”€â”€ models/
       â””â”€â”€ translation/
           â””â”€â”€ facebook/
               â””â”€â”€ m2m100_418M/
   ```
3. Place all downloaded files into that final folder (`m2m100_418M/`):
   ```
   pytorch_model.bin
   rust_model.ot
   config.json
   source.spm
   target.spm
   tokenizer_config.json
   special_tokens_map.json
   ```
4. When you launch ComfyUI, you should see this in the console:
   ```
   [TranslationNode] Using local model: models/translation/facebook/m2m100_418M
   ```
âœ… Once the model is in place, the node will **never download anything** â€” it will always load from your local drive.

## ğŸ’¡ Usage
1. Add the **Translation Node** to your workflow.  
2. Enter any text you want to translate.  
3. Choose a target language (default: `en`).  
4. The source language can be set to `auto` for automatic detection.  
5. Connect the output (`translated_text`) to other nodes â€” for example, to an image generation prompt.  
6. Enjoy entering prompts in your own language â€” the node will handle the translation automatically!

## ğŸ§  Model Details
- **Model:** `facebook/m2m100_418M`  
- **Type:** Multilingual encoder-decoder transformer  
- **Languages supported:** 100+  
- **Size on disk:** ~3.6 GB (pytorch_model.bin ~1.8 GB, rust_model.ot ~1.8 GB)  
- **Framework:** PyTorch via Hugging Face Transformers

## ğŸ”’ Privacy & Security
This node runs entirely **offline**.
- ğŸ§© All translations are processed locally on your computer.  
- ğŸ’¾ The model is loaded from `ComfyUI/models/translation/facebook/m2m100_418M`.  
- ğŸš« No text, metadata, or user data is ever sent to external servers or APIs.  
- ğŸ” Safe to use with confidential or private content.  
- ğŸ”Œ Once installed, you can use it **without any internet connection**.

## âš™ï¸ Requirements
```
transformers>=4.41.0
sentencepiece
torch
langdetect
```

## ğŸ‘¤ Author
Petr ProvaznÃ­k â€“ 2025

## ğŸ“„ License
MIT License Â© 2025  
Created for the ComfyUI community.
